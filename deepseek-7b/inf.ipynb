{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bitsandbytes as bnb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(69420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"../final_dataset/test_set.csv\")\n",
    "df3['Label'] = df3['Label'].replace({0: 'Non-sensitive', 1: 'Secret'})\n",
    "print(df3['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_window(text, target_string, window_size=200):\n",
    "\n",
    "    target_index = text.find(target_string)\n",
    "\n",
    "    if target_index != -1:\n",
    "        start_index = max(0, target_index - window_size)\n",
    "        end_index = min(len(text), target_index + len(target_string) + window_size)\n",
    "        context_window = text[start_index:end_index]\n",
    "        return context_window\n",
    "\n",
    "    return None\n",
    "\n",
    "df3['Contents'] = df3.apply(lambda row: create_context_window(row['Contents'], row['Secret']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = df3[df3['Contents'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "You are a code security auditor or classifier speccialized in identifying and categorizing sensitive secrets from code snippet.Classify the given candidate string as either \"Non-sensitive\" or \"Secret\" based on its role in the provided code snippet. A \"Secret\" includes sensitive information such as: API keys and secrets (e.g., `sk_test_ABC123`), Private and secret keys (e.g., private SSH keys, private cryptographic keys), Authentication keys and tokens (e.g., `Bearer <token>`), Database connection strings with credentials (e.g., `mongodb://user:password@host:port`), Passwords, usernames, and any other private information that should not be shared openly. A \"Non-sensitive\" string is not considered secret and can be shared openly. This may include: Publicly available keys (e.g., public SSH keys), Non-sensitive configuration values or identifiers, Any non-sensitive data not directly tied to security or authentication. Carefully consider the context of the string in the provided code. If the string is part of authentication, encryption, or access control, it is likely a \"Secret\". Otherwise, it is \"Non-sensitive\". Ensure you pay attention to specific patterns like tokens, passwords, or keys in the string. Return the answer as the corresponding label.\n",
    "\n",
    "candidate_string: {data_point[\"Secret\"]}\n",
    "code_snippet: {data_point[\"Contents\"]}\n",
    "label: {data_point[\"Label\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "You are a code security auditor or classifier speccialized in identifying and categorizing sensitive secrets from code snippet.Classify the given candidate string as either \"Non-sensitive\" or \"Secret\" based on its role in the provided code snippet. A \"Secret\" includes sensitive information such as: API keys and secrets (e.g., `sk_test_ABC123`), Private and secret keys (e.g., private SSH keys, private cryptographic keys), Authentication keys and tokens (e.g., `Bearer <token>`), Database connection strings with credentials (e.g., `mongodb://user:password@host:port`), Passwords, usernames, and any other private information that should not be shared openly. A \"Non-sensitive\" string is not considered secret and can be shared openly. This may include: Publicly available keys (e.g., public SSH keys), Non-sensitive configuration values or identifiers, Any non-sensitive data not directly tied to security or authentication. Carefully consider the context of the string in the provided code. If the string is part of authentication, encryption, or access control, it is likely a \"Secret\". Otherwise, it is \"Non-sensitive\". Ensure you pay attention to specific patterns like tokens, passwords, or keys in the string. Return the answer as the corresponding label.\n",
    "\n",
    "candidate_string: {data_point[\"Secret\"]}\n",
    "code_snippet: {data_point[\"Contents\"]}\n",
    "label: \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X_test.loc[:,'Label']\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=\"float16\",\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=\"float16\",\n",
    "#     quantization_config=bnb_config, \n",
    "# )\n",
    "\n",
    "# model.config.use_cache = False\n",
    "# model.config.pretraining_tp = 1\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "base_model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
    "checkpoint_path = \"../models/deepseek-fine-tuned-model-30k-new-prompt-1024-imb/checkpoint-21000\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "\n",
    "# Load fine-tuned model with quantization settings\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"float16\",\n",
    "    quantization_config=bnb_config,  # Keep quantization enabled\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load tokenizer from checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=False)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    total_time = 0  # Track total inference time\n",
    "    \n",
    "    for i in tqdm(range(len(test))):\n",
    "        prompt = test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens=4, \n",
    "                        temperature=0.1)\n",
    "        \n",
    "        start = time.time()\n",
    "        result = pipe(prompt)\n",
    "        end = time.time()\n",
    "\n",
    "        total_time += (end - start)\n",
    "        \n",
    "        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n",
    "        \n",
    "        # Determine the predicted label\n",
    "        if \"Secret\" in answer:\n",
    "            y_pred.append(\"Secret\")\n",
    "        else:\n",
    "            y_pred.append(\"Non-sensitive\")\n",
    "\n",
    "    avg_time = total_time / len(test)\n",
    "    print(f\"Average prediction time: {avg_time:.4f} seconds\")\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict(X_test, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to numpy array for easy comparison\n",
    "# y_true = np.array(y_true)\n",
    "# y_pred = np.array(y_pred)\n",
    "\n",
    "# # Identify False Negatives (FN) and False Positives (FP)\n",
    "# false_negatives = X_test[(y_true == \"Secret\") & (y_pred == \"Non-sensitive\")]\n",
    "# false_positives = X_test[(y_true == \"Non-sensitive\") & (y_pred == \"Secret\")]\n",
    "\n",
    "# # Save to a text file\n",
    "# output_file = \"false_predictions.txt\"\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\"False Negatives (FN):\\n\")\n",
    "#     f.write(\"\\n\".join(false_negatives[\"text\"]) + \"\\n\\n\")\n",
    "\n",
    "#     f.write(\"False Positives (FP):\\n\")\n",
    "#     f.write(\"\\n\".join(false_positives[\"text\"]) + \"\\n\")\n",
    "\n",
    "# print(f\"False negatives and false positives saved to {output_file}\")\n",
    "\n",
    "# Identify false positives and false negatives\n",
    "results = pd.DataFrame({\n",
    "    'true_label': y_true,\n",
    "    'predicted_label': y_pred,\n",
    "    'text': X_test['text']\n",
    "})\n",
    "\n",
    "# False Negatives: Actual = \"Secret\", Predicted = \"Non-sensitive\"\n",
    "false_negatives = results[(results['true_label'] == 'Secret') & \n",
    "                          (results['predicted_label'] == 'Non-sensitive')]\n",
    "\n",
    "# False Positives: Actual = \"Non-sensitive\", Predicted = \"Secret\"\n",
    "false_positives = results[(results['true_label'] == 'Non-sensitive') & \n",
    "                          (results['predicted_label'] == 'Secret')]\n",
    "\n",
    "# Display counts\n",
    "print(f\"Total False Negatives: {len(false_negatives)}\")\n",
    "print(f\"Total False Positives: {len(false_positives)}\")\n",
    "\n",
    "# # Save to text files\n",
    "# with open('false_negatives1024-np-1.txt', 'w', encoding='utf-8') as f:\n",
    "#     for idx, row in false_negatives.iterrows():\n",
    "#         f.write(f\"Example {idx+1}:\\n\")\n",
    "#         f.write(f\"True: {row['true_label']} | Predicted: {row['predicted_label']}\\n\")\n",
    "#         f.write(f\"{row['text']}\\n\\n\")\n",
    "#         f.write(\"-\" * 100 + \"\\n\\n\")\n",
    "\n",
    "# with open('false_positives1024-np-1.txt', 'w', encoding='utf-8') as f:\n",
    "#     for idx, row in false_positives.iterrows():\n",
    "#         f.write(f\"Example {idx+1}:\\n\")\n",
    "#         f.write(f\"True: {row['true_label']} | Predicted: {row['predicted_label']}\\n\")\n",
    "#         f.write(f\"{row['text']}\\n\\n\")\n",
    "#         f.write(\"-\" * 100 + \"\\n\\n\")\n",
    "\n",
    "# print(\"Files saved: false_negatives.txt and false_positives.txt\")\n",
    "\n",
    "# Optional: Create a confusion matrix visualization to better understand the model's performance\n",
    "cm = confusion_matrix(y_true, y_pred, labels=['Non-sensitive', 'Secret'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-sensitive', 'Secret'],\n",
    "            yticklabels=['Non-sensitive', 'Secret'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('../plots/deepseek-7e-new-prompt-1024-imb.png')\n",
    "plt.close()\n",
    "\n",
    "# Print some metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the checkpoint directory\n",
    "# checkpoint_path = \"models/llama-3.1-fine-tuned-model-30k-new/checkpoint-21000\"\n",
    "\n",
    "# # Load the fine-tuned model from the checkpoint\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint_path)\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, use_fast=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secretbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
